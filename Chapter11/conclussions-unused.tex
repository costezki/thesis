\section{Future work}
\label{sec:future-work}
    %\todo revise

    % boosting how cool graph patterns are
    % Pattern graphs and the matching methods developed in this thesis can be applied for expressing many more grammatical features than the ones presented here. They can serve as language for systematising grammatical realisations especially that the realisation statements play a vital role in SG grammars. The graph matching method itself can be applied to any other languages than English. So similar parsers can be implemented for other languages and and respectively grammars. 

    % speculating that the same method cam be applied to parse other languages
    Linguists study various language properties, to do so they need to annotate large amounts of text to come up with conclusive statements or formulate hypothesises. Provided the parser with a target set of feature coverage, the scale at which text analysis is performed can be uplifted orders of magnitude helping linguists come with statistically significant and grounded claims in much shorter time. Parsimonious Vole could play the role of such a text annotator helping the research on text genre, field and tenor.

    %\todo{critical analysis of current methods using graph matching, it is fast and has potential to extend to arbitrary number of features} 
    %\todo{Other important facts and figures not mentioned in the main body}
    %\section{Further work}

    % This section describes improvements of the project that are desirable or at least worth considering along with major improvements that arise in the process of theoretical development and parser implementation. 

% \subsection{Towards semantic verbal groups}



% \subsection{Nominal, Quality, Quantity and other groups of the Cardiff grammar}
    % Cardiff unit classes are semantically motivated as compared to the more syntactic ones in the Sydney grammar. This is stated in \citet[193--194]{Fawcett2000} and has been presented in Section \ref{sec:cardiff-theory-grammar} and further discussed in Section \ref{sec:discussion-unit-classes}.

    % For instance, Nominal class structure proposed in the Cardiff grammar (discussed in Section \ref{sec:nominal-group}), uses elements that are more semantic in nature (e.g. various types of determiners: representational, quantifying, typic, partitive etc.) than the syntactic one offered in the Sydney grammar (i.e. deictic determiner). To do this shift we need to think of two problems: (a) how to detect the semantic head of the nominal units and (b) how to craft (if none exists) a lexical-semantic resource to help determine potential functions (structural elements) for each lexical item in the nominal group. In my view building lexical-semantic resources asked at point (b) bears actually a solution for point (a) as well. Employing some of the existing resources such as Nigel grammar, even if it is built in Sydney style, could and most likely is suitable for fulfilling the needs at point (b). In additions other non SFL lexical resources such as such as WordNet \citep{Miller1995} or FrameNet \citep{Baker1998} could be considered in this context as well but the solution is not straightforward and further adaptations need to be done for them to be useful in SFL domain.

    % The same holds for Adverbial and Adjectival groups (discussed in Section \ref{sec:advectival-adverbial-groups}) which, in Cardiff grammar, are split into the Quality and Quantity groups. The existent lexical resources such as such as WordNet \citep{Miller1995} and/or FrameNet\citep{Baker1998} combined with the delicate classification proposed by \citet{Tucker1997} 
    % can yield positive results in parsing with Cardiff unit classes. 

    % Just as in the case of verb groups discussed in previous section, moving towards semantically motivated unit classes would greatly benefit applications requiring deeper natural language understanding.

% \subsection{Taxis analysis and potential for discourse relation detection}
    
    % Currently the Parsimonious Vole parser implements a simple taxis analysis technique based on graph pattern matching, similar to the one describe in Sections \ref{sec:pattern-graph-matching} and \ref{sec:pattern-based-operations}, employed for the MOOD and TRANSITIVITY feature enrichment. Description of this work, however, is not included in this thesis because it was not yet tested, so remains a highly desirable future work. 

    % %As presented in Appendix \ref{ch:texis-patterns} I have created 
    % In Appendix \ref{ch:texis-patterns} is listed a database of clause taxis patterns, represented as regular expressions, according to a systematisation in IFG 3 \citep{Halliday2004}. Each relation type has a set of patterns ascribed to it which represent clause order and presence or absence of explicit lexical markers or clause features. 

    % In the taxis analysis process, each pair of adjacent clauses in the sentence is tested for compliance with TAXIS pattern in the database. The matches, as there might be multiple ones for one system, represent potential manifestation of the corresponding relation with no way to distinguish at the moment which pattern is in fat more likely to be correct. A similar problem was described for TRANSITIVITY system and a potential solution was also described in terms of a discrimination mechanism in Section \ref{sec:systemic-evaluation-TRANSITIVITY}.

    % Currently this part of the parser has not been tested and so remains highly desirable future work. Further improvements and developments can be performed based on incremental testing and corrections of the taxis pattern database.

    % The methods employed in this thesis can be extended to handle relations between sentences taking on a discourse level analysis which is perfectly in line with the Rhetorical Structure Theory (RST) \citep{Mann1988,Mann1992}. 

    % To increase the accuracy of taxis analysis, I believe the following additional elements should be included into the pattern representation: Transitivity configurations including process type and participant roles, co-references resolved between clauses/sentences and Textual metafunction analysis in terms of Theme/Rheme and eventually New/Given.

% \subsection{Towards speech act analysis}
%     As Robin Fawcett explains \citep{Fawcett2011}, Halliday's approach to Mood analysis differs from that of Transitivity in the way that the former is not ``pushed forward towards semantics'' as the latter is. Having a semantically systematised MOOD system would take the interpersonal text analysis into a realm compatible with Speech Act Theory proposed by \citet{Austin1975} or its latter advancements such the \citet{Searle1969} which, in mainstream linguistics, are placed under the umbrella of pragmatics. 

%     Halliday proposes a simple system of speech functions \citep[p.136]{Halliday2013} which Fawcett develops into a quite delicate system network \citep{Fawcett2011}. It is worth exploring ways to implement Fawcett's latest developments and because the two are not conflicting but complementing each other, one could use the Hallidayan MOOD system as a foundation, especially because it has already been implemented and described in the current work. 

% \subsection{Process Types and Participant Roles}
%     The PTDB \citep{Neale2002} is the first lexical-semantic resource for the Cardiff grammar Transitivity system. Its usability in the original form doesn't go beyond that of a resource to be consulted by linguists in the process of manual analysis. It was rich in human understandable comments and remarks but not formal enough to be usable by computers. In the scope of current work the PTDB has been cleaned and brought into a machine readable form, but this is far from exhausting its potential as a lexical-grammatical resource for semantic parsing. 

%     In mainstream computational linguistics, there exist several other lexical-semantic resources used for Semantic Role Labelling (SRL), such as FrameNet \citep{Baker1998}, VerbNet \citep{Kipper2008}. Mapping or combining PTDB with these resources into a new one would yield benefits for both sides combining strengths of each and covering their shortcomings.

%     Combining PTDB with VerbNet for example, would be my first choice for the following reasons. PTDB is well semantically systematised according to Cardiff Transitivity system however it lacks any links to syntactic manifestations. VerbNet, on the other hand, contains an excellent mapping to the syntactic patterns in which each verb occurs, each with associated semantic representations of participant roles and some first order predicates. %However, the systematisation of frames and participant roles could benefit from a more robust basis of categorisation. 
%     Also the lexical coverage of VerbNet is wider than that of PTDB. 

%     Turning towards resources like FrameNet and WordNet could bring other benefits. For example FrameNet has a set of annotated examples for every frame which, after transformation into the Transitivity system, could be used as a training corpus for machine learning algorithms. Another potential benefit would be generating semantic constraints (for example in terms of WordNet \citep{Miller1995} synsets or GUM \citep{Bateman1995,Bateman2010} classes) for every participant role in the system.

%     PTDB can benefit from mappings with GUM ontology which formalises the experiential model of Sydney school. First by increasing delicacy (at at the moment it covers only three top levels of the system) and second by importing constraints on process types and participant roles from the Nigel grammar \citep{Matthiessen1985}. To achieve this, one would have to first map the Cardiff and the Sydney Transitivity systems and second extract lexical entries from the Nigel grammar along with adjacent systemic selections. 

\subsection{Reasoning with systemic networks}
    Systemic networks are a powerful instrument to represent the paradigmatic dimension of language. Besides hierarchies they can include constraints on which selections can actually go together or a more complex set of non-hierarchical selection inter-dependencies. Moreover systemic choices can be also accompanied by realisation rules useful for generation purpose but they could potentially be used in parsing as well. 

    In this thesis system networks are used solely for representation purposes and what would be highly desirable is to enable reasoning capabilities for constraint checking on systemic selections and on syntactic and semantic constituency. For example one could as whether a certain set of features are compatible with each other, or provided a systemic network and several feature selections what would be the whole set of system choices, or being in a particular point in the system network what are the possible next steps towards more delicate systemic choices, or for a particular choice or set of choices what should be present or absent in the constituency structure of the text and so on. All these questions could potentially be resolved by a systemic reasoner. 

    Martin Kay was the first to attempt formalisation of systemics that would become known as Functional Unification Grammar (FUG) \citep{Kay1985}. This formalisation was adopted in other linguistic frameworks such as HPSG, Lexical Functional Grammars and Typed Feature Structures. %One could look at what has been done and adapt the or build a new reasoning system for systemic networks. 

    With the same goal in mind, one could also look at existing reasoners for different logics and attempt an axiomatization of the systemic networks; and more specifically one could do that in Prolog language or with description logics (DL) as there is a rich set of tools and resources available in the context of Semantic Web.

\subsection{Creation of richly annotated corpus}
    In order to evaluate a parser, a gold standard annotation corpus is essential.  The bigger the corpus, covering various text genres, the more reliable are the evaluation results. A corpus can as well be the source of grammar or distribution probabilities for structure element and potential filling units as explored by \citet{Day2007}, \citet{Souter1996} and other scholars in Cardiff. Moreover such a corpus can also constitute the training data set for a machine learning algorithm for parsing.

    A corpus of syntactically annotated texts with the Cardiff grammar already exists but, from personal communication with Prof. Robin Fawcett, it has not yet been released to the public because it still is considered incomplete. Even so this corpus covers only the constituency structures and what I would additionally find very useful, would be a set of systemic features of the constituting units covering a full SFG analysis in terms of experiential, interpersonal and textual metafunctions; and not only the unit class and the element it fills.

    A small richly annotated set of text had been created in the scope of the current work for the purpose of evaluating the parser. However it is by far not enough to offer a reliable evaluation. Therefore it is highly desirable to create one. 

    To approach this task one could use a systemic functional annotation tool such as the UAM Corpus Tool \citep{ODonnell2008,ODonnell2008a} developed and still maintained by Mick O'Donnell or any other tool that supports segment annotation with systemic network tag set structure.

    To aid this task one could bootstrap this task by converting other existing corpuses such as the Penn Treebank. This task had been already explored by Honnibal in \citeyear{Honnibal2004a,Honnibal2007}.

% \subsection{The use of Markov Logic for pattern discovery}
%     Markov Logic \citep{Richardson2006,Domingos2010} is a probabilistic logic which applies ideas of Markov networks to first order logic enabling uncertain inference. What is very interesting about this logic is that tools implementing it have learning capabilities not only of formulas weights but also of new logical clauses. 

%     In the current approach I am using graph pattern matching techniques to generate a rich set of features for the constituent units. However creating those patterns is a considerable effort. Since graph patterns can be expressed via first order functions and individuals, and assuming that there would already exist a richly annotated corpus, Markov Logic instruments (for example Alchemy\footnote{\url{http://alchemy.cs.washington.edu/}}, Tuffy\footnote{\url{http://i.stanford.edu/hazy/hazy/tuffy/}} and others) could be employed to inductively learn such patterns from the corpus. 

%     This approach resembles the Vertical Strips (VS) of \citet{ODonoghue1991a}. The similarity is the probabilistic learning of patterns from a corpus. The difference is that VS patterns are syntactic segment chains from the root node down to tree leafs while with ML more complex patterns can be learned independently of their position in the syntactic tree. Moreover such patterns can be bound to the specific feature set. 

    %todo \todo{propose a natural language task classification based on the number of features needed as input and provided as output}
    
    %
    %\section{Overall evaluations}
    %todo \todo{A deduction made on the basis of the main body (i.e. Concluding statements)}
    %todo \todo{The writerâ€™s personal opinion on what has been discussed}
